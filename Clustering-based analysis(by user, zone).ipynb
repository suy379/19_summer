{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering-based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def minMaxScaler(numArr):\n",
    "    minx = np.min(numArr)\n",
    "    maxx = np.max(numArr)\n",
    "    numArr = (numArr - minx) / (maxx - minx)\n",
    "    return numArr\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans as MBK\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "df = pd.read_csv('/content/drive/Shared drives/gh_new_zone/--.csv',index_col = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the columns for clustering\n",
    "input_columns = ['start_time','rev_total','utime']\n",
    " #by user analysis, groupby column is 'member_id'\n",
    "    #by zone analysis, groupby column is 'zone_id'\n",
    "groupby_df = df.groupby('member_id').mean()[input_columns] \n",
    "\n",
    "scaled_df = groupby_df.copy()\n",
    "scaled_df[input_columns] = minMaxScaler(groupby_df[input_columns])\n",
    "\n",
    "if len(input_columns) != 2:\n",
    "    pass\n",
    "else:\n",
    "    plt.scatter(groupby_df[input_columns[0]][:1000],groupby_df[input_columns[1]][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalK(data, nrefs=3, maxClusters=7):\n",
    "    \"\"\"\n",
    "    Calculates KMeans optimal K using Gap Statistic from Tibshirani, Walther, Hastie\n",
    "    Params:\n",
    "        data: ndarry of shape (n_samples, n_features)\n",
    "        nrefs: number of sample reference datasets to create\n",
    "        maxClusters: Maximum number of clusters to test for\n",
    "    Returns: (gaps, optimalK)\n",
    "    \"\"\"\n",
    "    gaps = np.zeros((len(range(1, maxClusters+1)),))\n",
    "    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n",
    "    for gap_index, k in enumerate(range(1, maxClusters+1)):\n",
    "\n",
    "        # Holder for reference dispersion results\n",
    "        refDisps = np.zeros(nrefs)\n",
    "\n",
    "        # For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i in range(nrefs):\n",
    "            \n",
    "            # Create new random reference set\n",
    "            randomReference = np.random.random_sample(size=data.shape)\n",
    "            \n",
    "            # Fit to it\n",
    "            #km = KMeans(k)\n",
    "            km = MBK(k)\n",
    "            km.fit(randomReference)\n",
    "            \n",
    "            refDisp = km.inertia_\n",
    "            refDisps[i] = refDisp\n",
    "\n",
    "        # Fit cluster to original data and create dispersion\n",
    "        #km = KMeans(k)\n",
    "        km = MBK(k)\n",
    "        km.fit(data)\n",
    "        \n",
    "        origDisp = km.inertia_\n",
    "\n",
    "        # Calculate gap statistic\n",
    "        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n",
    "\n",
    "        # Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "        \n",
    "        resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n",
    "    if True in list(resultsdf['gap'].diff()<0):\n",
    "        return (gaps.argmax() + 1, resultsdf) # Plus 1 because index of 0 means 1 cluster is optimal, index 2 = 3 clusters are optimal\n",
    "    else:\n",
    "        return (4, resultsdf) # or 5\n",
    "\n",
    "k, gapdf = optimalK(np.array(list(groupby_df[input_columns].values)), nrefs=1, maxClusters=7)\n",
    "print ('Optimal k is: ', k)\n",
    "plt.plot(gapdf['gap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_s = dict(zip(list(scaled_df.index),list(scaled_df[input_columns].values)))\n",
    "dict_t = dict(zip(list(groupby_df.index),list(groupby_df[input_columns].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_clust(a):\n",
    "    \n",
    "    #A : Behavior\n",
    "    X=list(dict_s.values())\n",
    "    kmeans = KMeans(n_clusters=a,random_state=0).fit(X)\n",
    "    df = pd.DataFrame(np.array(list(dict_t.values())))\n",
    "    df['cluster']=kmeans.labels_\n",
    "    cluster_info=pd.DataFrame()\n",
    "    for i in range(a):\n",
    "        cluster_info['cluster'+str(i+1)] = list(df[df['cluster']==i].mean()[:-1])\n",
    "    for i in range(a):\n",
    "         for j in range(len(df.columns)-1):\n",
    "            cluster_info.loc[len(df.columns)+j,cluster_info.columns[i]]=np.sqrt(df[df['cluster']==i][j].var())\n",
    "    cluster_info = cluster_info.append(pd.Series(list(df['cluster'].value_counts(sort=False)), index=list(cluster_info.columns),dtype='str'), ignore_index=True) \n",
    "    \n",
    "    index_dict = dict(zip(range(len(df.columns)-1),list(groupby_df.columns)[:len(df.columns)-1]))\n",
    "    index_dict.update(dict(zip(range(len(df.columns)-1,2*(len(df.columns)-1)), list(map('SD of '.__add__,list(groupby_df.columns)[:len(df.columns)-1])))))\n",
    "    index_dict.update(dict({len(cluster_info)-1:'# of member'}))\n",
    "    cluster_info = cluster_info.rename(index=index_dict)\n",
    "    return display(cluster_info)\n",
    "\n",
    "factory =interactive(auto_clust, a=widgets.IntSlider(min=2,max=10,value=k,description=\"클러스터 수\"))\n",
    "display(factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering analysis by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering dataframe\n",
    "X=list(dict_s.values())\n",
    "kmeans = KMeans(n_clusters=scope[0],random_state=0).fit(X)\n",
    "cluster_df = pd.DataFrame(np.array(list(dict_t.values())),index = list(dict_t.keys()))\n",
    "cluster_df['cluster']=kmeans.labels_\n",
    "id_list = list(cluster_df[cluster_df['cluster']==scope[1]-1].index) \n",
    "scoped_df = df[df['member_id'].isin(id_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster by region\n",
    "region2_df = pd.concat([scoped_df['region'].value_counts(), df['region'].value_counts()],axis=1)\n",
    "region2_df.columns = ['cluster','total']\n",
    "region2_df['ratio'] = region2_df['cluster']*100/region2_df['total']\n",
    "region2_df = region2_df.sort_values(by='ratio',ascending=False)\n",
    "region2_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"클러스터 ?번의 평균연령은 \",end ='')\n",
    "print(scoped_df[scoped_df['age']<60]['age'].mean())\n",
    "print(\"전체 이용건의 평균연령은 \",end ='')\n",
    "print(df[df['age']<60]['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster by car model\n",
    "car_model_df = pd.concat([scoped_df['car_model'].value_counts()/len(scoped_df), ])\n",
    "pd.concat([scoped_df[scoped_df['car_id'].isin(list(scoped_df['car_id'].drop_duplicates()))]['car_model'].value_counts()*100/len(scoped_df),\n",
    "           df[df['car_id'].isin(list(scoped_df['car_id'].drop_duplicates()))]['car_model'].value_counts()*100/len(df)],axis =1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering analysis by zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering dataframe\n",
    "X=list(dict_s.values())\n",
    "kmeans = KMeans(n_clusters=15,random_state=0).fit(X)\n",
    "cluster_df = pd.DataFrame(np.array(list(dict_t.values())),index = list(dict_t.keys()))\n",
    "cluster_df['cluster']=kmeans.labels_\n",
    "cluster_df.columns=input_columns + ['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_df=pd.read_csv('/content/drive/Shared drives/gh_new_zone/--.csv')\n",
    "\n",
    "zone_df[zone_df['id'].isin(list(cluster_df[cluster_df['cluster']==ㅇㅅㅇ].index))]['region'].value_counts()[:10]\n",
    "zone_df[zone_df['id'].isin(list(cluster_df[cluster_df['cluster']==ㅎㅅㅎ].index))]['region'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([zone_df[zone_df['id'].isin(list(cluster_df[cluster_df['cluster']==ㅇㅅㅇ].index))]['district_type'].value_counts(),\n",
    "           zone_df[zone_df['id'].isin(list(cluster_df[cluster_df['cluster']==ㅎㅅㅎ].index))]['district_type'].value_counts()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
